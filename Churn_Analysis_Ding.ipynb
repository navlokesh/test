{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4f8f43",
   "metadata": {},
   "source": [
    "## Customer Churn Analysis : Ding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv('Test Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e10e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "102606ae",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a511fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicated rows in the dataset\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the customer identifaction column as we wouldn't need it for our analysis\n",
    "df.drop('customer_id', inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce396135",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows :',df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc358c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of columns :',df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the spread of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ff161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the datatype of each columns and number of non-null values in each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0287ff",
   "metadata": {},
   "source": [
    "#### Seems like we have very few missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538bfde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking number of null values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the rows with null values\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f275e5",
   "metadata": {},
   "source": [
    "#### Since we have only 4 rows with missing data, we can drop them as it is a very small proportion of total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the rows with null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0286fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43e821b4",
   "metadata": {},
   "source": [
    "#### We have few categorical variables in our dataset. We need to convert it to numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ce42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df:\n",
    "    if df[feature].dtype == 'object':\n",
    "        df[feature] = pd.Categorical(df[feature]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab7782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd568c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e9102",
   "metadata": {},
   "source": [
    "#### We have all the variables in numerical format and there are no null values as we dropped them earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ad729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a145503",
   "metadata": {},
   "source": [
    "### We need to perform predictive analytics using Machine Learning models to understand who are likely to churn.\n",
    "### However, it is important to understand how are our users churning.\n",
    "### Let us Perform some Discriptive Analysis using the data to understand how the customers are churning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508a274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e93bef",
   "metadata": {},
   "source": [
    "### Discriptive Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e51088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the proportion of users who had churned\n",
    "df.churned.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb632874",
   "metadata": {},
   "source": [
    "#### 72.6% of our customers are churning which is quite high\n",
    "#### Let us try to understand how the churn rate is different for domestic and international "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('is_domestic', hue='churned', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44f4e1",
   "metadata": {},
   "source": [
    "#### The plot shows that domestic users are churning at high rate. Let us check the churn rate in numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3dca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('is_domestic')['churned'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7563ffda",
   "metadata": {},
   "source": [
    "#### Churn rate of Domestic users is at 84% while overall global churn rate is at 72.6%. Domestic users are churning faster.\n",
    "#### Let us try to understand further based on the platform users use for top ups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a6f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('platform', hue='churned', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da799c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('platform')['churned'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['is_domestic','platform'])['churned'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52c073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50d37ae8",
   "metadata": {},
   "source": [
    "#### The Web users churn at 79% while App users are churning at the rate of 57.4%\n",
    "#### However, domestic web users are churning at 87%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4d123",
   "metadata": {},
   "source": [
    "### We understand that web users have higher churn rate than App users.\n",
    "### To further understand this, we need to answer few questions. For example:\n",
    "##### - If the same customer uses Application regulargly and use Website occationally, are they considered 2 different users?\n",
    "##### - What are the ways to encourage users to use Application\n",
    "etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9103b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f399a07",
   "metadata": {},
   "source": [
    "## Predictive Analytics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d2633",
   "metadata": {},
   "source": [
    "### Model Building and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb4d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7831d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating dependent and independent variables\n",
    "x = df.drop('churned', axis = 1, inplace=False).copy()\n",
    "y = df.pop('churned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train',x_train.shape)\n",
    "print('x_test',x_test.shape)\n",
    "print('y_train',y_train.shape)\n",
    "print('y_test',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a41b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cd8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea118430",
   "metadata": {},
   "source": [
    "#### We have variables on different scale in terms of magnitude. Let us consider algorithms which are tolerent to outliers and scale of the variables. Starting with Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc95682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97abc1ff",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1180ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc3d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameter tuning for best combination of model parameters using param grid and cross validation\n",
    "param_grid = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [4,6,8,10],\n",
    "    'min_samples_leaf': [50,100,150],\n",
    "    'min_samples_split': [150,200,300],\n",
    "    'random_state': [0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, cv = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f806b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(x_train, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27033b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_dtcl = grid_search.best_estimator_\n",
    "best_grid_dtcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd92836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking feature importances\n",
    "print (pd.DataFrame(best_grid_dtcl.feature_importances_, columns = [\"Imp\"], index = x_train.columns).sort_values('Imp',ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e690e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction\n",
    "ytrain_predict_dtcl = best_grid_dtcl.predict(x_train)\n",
    "ytest_predict_dtcl = best_grid_dtcl.predict(x_test)\n",
    "\n",
    "ytrain_predict_prob_dtcl = best_grid_dtcl.predict_proba(x_train)\n",
    "ytest_predict_prob_dtcl = best_grid_dtcl.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d7aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d144a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model metrics for Decision Tree\n",
    "print('Training accuracy:',accuracy_score(y_train, ytrain_predict_dtcl))\n",
    "print('Testing accuracy:', accuracy_score(y_test, ytest_predict_dtcl)) \n",
    "print('Confusion matrix for training set: \\n',confusion_matrix(y_train, ytrain_predict_dtcl)) \n",
    "print('Confusion matrix for test set: \\n',confusion_matrix(y_test, ytest_predict_dtcl)) \n",
    "print('classification report for training set: \\n',classification_report(y_train, ytrain_predict_dtcl))\n",
    "\n",
    "print('classification report for test set: \\n',classification_report(y_test, ytest_predict_dtcl))\n",
    " \n",
    "print('training roc_auc_score:',roc_auc_score(y_train, ytrain_predict_prob_dtcl[:,1]))\n",
    "print('test set roc_auc_score:',roc_auc_score(y_test, ytest_predict_prob_dtcl[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b9fbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0113e3fc",
   "metadata": {},
   "source": [
    "#### Decision tree model metric analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa13e51",
   "metadata": {},
   "source": [
    "### The Prediction accuracy for both training and test sets is around 80%\n",
    "### Also, out of all the +ve predictions, 82% are truly positive (precision).\n",
    "### Oout of all the positives in the dataset, 92% are captured by the model to predict them as positive making our model have a very strong Recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99ac024",
   "metadata": {},
   "source": [
    "#### However, In feature importances, we see that there are few features contributing very less to the model's decision making in terms of prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba245d",
   "metadata": {},
   "source": [
    "#### Let us use the Random Forest classifier which is based on decision trees considered in an enseamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aeb279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3df769ad",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd873a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f99d12",
   "metadata": {},
   "source": [
    "### Since we can have multiple trees with different features, we can use higher explanability from our model as random forest model considers multiple decision trees and uses voting for class prediciton (Mode). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a84d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \n",
    "    'max_depth': [4,6,8,10],\n",
    "    'min_samples_leaf': [50,100,150],\n",
    "    'min_samples_split': [150,200,300],\n",
    "    \n",
    "    'max_features': [4, 6, 8],\n",
    "    'n_estimators': [101, 301],\n",
    "\n",
    "    'random_state': [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9317171",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = rfcl, param_grid = param_grid, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30046e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3956f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12deb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_rfcl = grid_search.best_estimator_\n",
    "best_grid_rfcl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facf6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pd.DataFrame(best_grid_rfcl.feature_importances_, columns = [\"Imp\"], index = x_train.columns).sort_values('Imp',ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75604c85",
   "metadata": {},
   "source": [
    "#### We see that feature importance for low contributing features from decision tree has increased in random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73163ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "ytrain_predict_rfcl = best_grid_rfcl.predict(x_train)\n",
    "ytest_predict_rfcl = best_grid_rfcl.predict(x_test)\n",
    "\n",
    "ytrain_predict_prob_rfcl = best_grid_rfcl.predict_proba(x_train)\n",
    "ytest_predict_prob_rfcl = best_grid_rfcl.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bdf525",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy:',accuracy_score(y_train, ytrain_predict_rfcl))\n",
    "print('Testing accuracy:', accuracy_score(y_test, ytest_predict_rfcl)) \n",
    "print('Confusion matrix for training set: \\n',confusion_matrix(y_train, ytrain_predict_rfcl)) \n",
    "print('Confusion matrix for test set: \\n',confusion_matrix(y_test, ytest_predict_rfcl)) \n",
    "print('classification report for training set: \\n'classification_report(y_train, ytrain_predict_rfcl))\n",
    "print('classification report for test set: \\n'classification_report(y_test, ytest_predict_rfcl))\n",
    "print('training roc_auc_score:',roc_auc_score(y_train, ytrain_predict_prob_rfcl[:,1]))\n",
    "print('test roc_auc_score:',roc_auc_score(y_test, ytest_predict_prob_rfcl[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be9186",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier model metric analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e9a11",
   "metadata": {},
   "source": [
    "### The Prediction accuracy for both training and test sets is still around 80%, almost same as decision tree. So is the precision.\n",
    "### However, recall  has increased to 94%, making it a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537ec3d",
   "metadata": {},
   "source": [
    "#### Let us consider another enseamble algorithm XGBoost classifier to check if it gives better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6540a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82d7f56f",
   "metadata": {},
   "source": [
    "#### XGBost Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f242d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XGB_model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "XGB_model.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_train_predict_XGB = XGB_model.predict(x_train)\n",
    "y_test_predict_XGB = XGB_model.predict(x_test)\n",
    "\n",
    "y_train_predict_prob_XGB = XGB_model.predict_proba(x_train)\n",
    "y_test_predict_prob_XGB = XGB_model.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy:',accuracy_score(y_train, y_train_predict_XGB))\n",
    "print('Testing accuracy:',accuracy_score(y_test, y_test_predict_XGB)) \n",
    "print('Confusion matrix for training set: \\n',confusion_matrix(y_train, y_train_predict_XGB)) \n",
    "print('Confusion matrix for test set: \\n',confusion_matrix(y_test, y_test_predict_XGB)) \n",
    "print('classification report for training set: \\n',classification_report(y_train, y_train_predict_XGB))\n",
    "print('classification report for test set: \\n',classification_report(y_test, y_test_predict_XGB))\n",
    "print('training roc_auc_score:',roc_auc_score(y_train, XGB_model.predict_proba(x_train)[:,1]))\n",
    "print('test roc_auc_score:',roc_auc_score(y_test, XGB_model.predict_proba(x_test)[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c9f24",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier model metric analysis:\n",
    "#### The metrics are almost same as our random forest classified it is not performing as best as random forest in terms of the metric 'recall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3433cc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3aec800",
   "metadata": {},
   "source": [
    "### Scope for Model Optimization techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aac800",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18f3c6bb",
   "metadata": {},
   "source": [
    "### Since we selected algorithms where the dimensions of the data does not affect the model's performance, scaling the data is not necessary\n",
    "### However, we know that data is not completely balanced. we have 76.2% churners.\n",
    "### From the metrics, we notice that models are performing great for class 1. But, recall and precision are not great for class 0\n",
    "### Possible reason for this could be the data imbalance and there are less 0s than 1s in our data.\n",
    "### Although 3:7 is a good ratio for binary class feature, balancing the data would give equal visibility of classes to our Machine Learning models\n",
    "\n",
    "#### We can use SMOTE technique to  balance the data and re-run our models to check if we get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7acd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0275164",
   "metadata": {},
   "source": [
    "### Conclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d86eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "683b3ee5",
   "metadata": {},
   "source": [
    "### In Churn analysis, we would want to make sure to capture most of the churners. The metric for this is Recall / Sensitivity\n",
    "### In those terms, we can say our random forest classifier is doing a great job by capturing 94% of churners in its predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
